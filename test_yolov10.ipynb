{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\danil\\Documents\\Github\\NaturalisticAdversarialPatches\\crop001692.png: 640x224 5 persons, 3 cars, 1 handbag, 50.2ms\n",
      "Speed: 2.0ms preprocess, 50.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "model_name = \"yolov10\"\n",
    "cls_id_attacked = 0\n",
    "cls_conf_threshold = 0.5\n",
    "batch_size = 1\n",
    "device = get_default_device()\n",
    "\n",
    "detector = YOLO(\"yolov10s.pt\")\n",
    "\n",
    "# Use the model\n",
    "results = detector(\"crop001692.png\")  # Predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 1 probability: tensor([0.8992], device='cuda:0')\n",
      "Object 2 probability: tensor([0.8829], device='cuda:0')\n",
      "Object 3 probability: tensor([0.8680], device='cuda:0')\n",
      "Object 4 probability: tensor([0.7835], device='cuda:0')\n",
      "Object 5 probability: tensor([0.6953], device='cuda:0')\n",
      "Object 6 probability: tensor([0.6449], device='cuda:0')\n",
      "Object 7 probability: tensor([0.5094], device='cuda:0')\n",
      "Object 8 probability: tensor([0.3783], device='cuda:0')\n",
      "Object 9 probability: tensor([0.2787], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, box in enumerate(results[0].boxes):\n",
    "    obj_prob = box.conf\n",
    "    print(f\"Object {i+1} probability: {obj_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\danil\\Documents\\Github\\NaturalisticAdversarialPatches\\crop001692.png: 640x224 5 persons, 3 cars, 1 handbag, 22.0ms\n",
      "Speed: 1.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
      "Boxes retrieved: [ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "obb: None\n",
      "orig_img: array([[[ 22,  17,  19],\n",
      "        [ 22,  17,  19],\n",
      "        [ 22,  17,  19],\n",
      "        ...,\n",
      "        [223, 224, 204],\n",
      "        [234, 230, 212],\n",
      "        [235, 230, 215]],\n",
      "\n",
      "       [[ 21,  16,  18],\n",
      "        [ 21,  16,  18],\n",
      "        [ 20,  15,  17],\n",
      "        ...,\n",
      "        [232, 233, 217],\n",
      "        [242, 244, 225],\n",
      "        [245, 248, 232]],\n",
      "\n",
      "       [[ 20,  15,  17],\n",
      "        [ 20,  15,  17],\n",
      "        [ 20,  15,  17],\n",
      "        ...,\n",
      "        [234, 233, 229],\n",
      "        [236, 237, 233],\n",
      "        [235, 240, 238]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[197, 209, 209],\n",
      "        [196, 208, 208],\n",
      "        [192, 204, 204],\n",
      "        ...,\n",
      "        [ 22,  27,  26],\n",
      "        [ 44,  44,  44],\n",
      "        [ 43,  39,  38]],\n",
      "\n",
      "       [[189, 201, 201],\n",
      "        [185, 197, 197],\n",
      "        [185, 197, 197],\n",
      "        ...,\n",
      "        [ 23,  22,  24],\n",
      "        [ 35,  32,  34],\n",
      "        [ 40,  35,  37]],\n",
      "\n",
      "       [[197, 214, 211],\n",
      "        [205, 220, 216],\n",
      "        [215, 229, 225],\n",
      "        ...,\n",
      "        [ 21,  20,  24],\n",
      "        [ 26,  25,  27],\n",
      "        [ 30,  30,  30]]], dtype=uint8)\n",
      "orig_shape: (862, 302)\n",
      "path: 'c:\\\\Users\\\\danil\\\\Documents\\\\Github\\\\NaturalisticAdversarialPatches\\\\crop001692.png'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\detect\\\\predict'\n",
      "speed: {'preprocess': 1.0085105895996094, 'inference': 22.00031280517578, 'postprocess': 0.99945068359375}]\n"
     ]
    }
   ],
   "source": [
    "# Obtain all bboxes\n",
    "if model_name == \"yolov10\":\n",
    "    bboxes = detector(\"crop001692.png\")\n",
    "\n",
    "print(f\"Boxes retrieved: {bboxes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3275692415553213 0.44910807952526827 0.4222521750342767 0.4074094201461898\n",
      "0 0.7879468399957316 0.5467519738004821 0.3868217215632761 0.42021480126613253\n",
      "0 0.7299749614387159 0.8801006131271751 0.5384752892500517 0.23979877374564965\n",
      "0 0.9152103449335162 0.19541205386274652 0.16742064621274835 0.2850735480713457\n",
      "0 0.6521441225973975 0.12847087001579266 0.28304922343879346 0.24947608540616842\n",
      "Labels: [[          0     0.32757     0.44911     0.42225     0.40741     0.89924]\n",
      " [          0     0.78795     0.54675     0.38682     0.42021     0.88286]\n",
      " [          0     0.72997      0.8801     0.53848      0.2398     0.69532]\n",
      " [          0     0.91521     0.19541     0.16742     0.28507     0.64492]\n",
      " [          0     0.65214     0.12847     0.28305     0.24948     0.37826]]\n",
      "Labels rescale: [[          0     0.89924      35.166      211.54      162.69      562.72]\n",
      " [          0     0.88286      179.55      290.19      296.37      652.41]\n",
      " [          0     0.69532      139.14      655.29      301.76         862]\n",
      " [          0     0.64492      251.11      45.578      301.67      291.31]\n",
      " [          0     0.37826      154.21      3.2177      239.69      218.27]]\n"
     ]
    }
   ],
   "source": [
    "# Objective: Retrieve labels and labels_rescale in this format:\n",
    "labels = []  # format:  (label, x_center, y_center, w, h)  ex:(0 0.5 0.6 0.07 0.22)\n",
    "labels_rescale = (\n",
    "    []\n",
    ")  # format:  (label, confidence, left, top, right, bottom)  ex:(person 0.76 0.6 183.1 113.5 240.3 184.7)\n",
    "\n",
    "if len(bboxes) == batch_size:\n",
    "    bbox = bboxes[0]\n",
    "\n",
    "for b in bbox.boxes:\n",
    "    detected_class = int(b.cls.cpu().item())\n",
    "    orig_width, orig_height = bbox.boxes.orig_shape[1], bbox.boxes.orig_shape[0]\n",
    "    if detected_class == int(cls_id_attacked):\n",
    "        conf = b.conf.cpu().item()\n",
    "        # For labels: using xywh format\n",
    "        x_center, y_center, w, h = (\n",
    "            b.xywh[0][0].cpu().item() / orig_width,\n",
    "            b.xywh[0][1].cpu().item() / orig_height,\n",
    "            b.xywh[0][2].cpu().item() / orig_width,\n",
    "            b.xywh[0][3].cpu().item() / orig_height,\n",
    "        )\n",
    "        label = np.array(\n",
    "            [detected_class, x_center, y_center, w, h, conf], dtype=np.float32\n",
    "        )\n",
    "        labels.append(label)\n",
    "        # For labels_rescale: using xyxy format\n",
    "        left, top, right, bottom = (\n",
    "            b.xyxy[0][0].cpu().item(),\n",
    "            b.xyxy[0][1].cpu().item(),\n",
    "            b.xyxy[0][2].cpu().item(),\n",
    "            b.xyxy[0][3].cpu().item(),\n",
    "        )\n",
    "        label_rescale = np.array(\n",
    "            [detected_class, conf, left, top, right, bottom], dtype=np.float32\n",
    "        )\n",
    "        labels_rescale.append(label_rescale)\n",
    "        \n",
    "        print(f\"{detected_class} {x_center} {y_center} {w} {h}\")\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels_rescale = np.array(labels_rescale)\n",
    "\n",
    "print(f\"Labels: {labels}\")\n",
    "print(f\"Labels rescale: {labels_rescale}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\danil\\Documents\\Github\\NaturalisticAdversarialPatches\\crop001692.png: 640x224 5 persons, 3 cars, 1 handbag, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
      "Loss Det: 0.7001213431358337\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss_det\n",
    "target_class = cls_id_attacked\n",
    "\n",
    "results = detector(\"crop001692.png\")\n",
    "combined_probs = []\n",
    "for box in results[0].boxes:\n",
    "    obj_prob = box.conf.cpu()\n",
    "    if box.cls.cpu().item() == target_class:\n",
    "            combined_probs.append(obj_prob)\n",
    "if combined_probs:\n",
    "        loss_det = torch.mean(torch.stack(combined_probs))\n",
    "else:\n",
    "    loss_det = torch.tensor(0.0).to(device)\n",
    "\n",
    "print(f\"Loss Det: {loss_det}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
